{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del notebook con OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key: sk-proj-****************************************************************************************************************************************************-amA_5sA\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "sys.path.append('../src')\n",
    "from procesador_de_cvs_con_llm import ProcesadorCV\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../../../../../../../apis/.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "unmasked_chars = 8\n",
    "masked_key = api_key[:unmasked_chars] + '*' * (len(api_key) - unmasked_chars*2) + api_key[-unmasked_chars:]\n",
    "print(f\"API key: {masked_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del módulo de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente inicializado como <openai.OpenAI object at 0x00000168642D44D0>\n",
      "Respuesta:\n",
      " {\n",
      "    \"puntuacion\": 100,\n",
      "    \"experiencia\": [\n",
      "        {\n",
      "            \"empresa\": \"Talking to Chatbots, by Reddgr\",\n",
      "            \"puesto\": \"Web Publisher and Generative AI Researcher\",\n",
      "            \"duracion\": 218\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"IBM\",\n",
      "            \"puesto\": \"Relationship Manager | Cognitive Solutions SaaS\",\n",
      "            \"duracion\": 43\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"Acoustic\",\n",
      "            \"puesto\": \"Principal Consultant | Martech SaaS\",\n",
      "            \"duracion\": 35\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"IBM\",\n",
      "            \"puesto\": \"Engagement Manager | B2B SaaS Retail Analytics\",\n",
      "            \"duracion\": 9\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"IBM\",\n",
      "            \"puesto\": \"Engagement Manager, in support of Acoustic | B2B SaaS Retail Analytics\",\n",
      "            \"duracion\": 10\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"MBD Analytics\",\n",
      "            \"puesto\": \"Business Intelligence Consultant\",\n",
      "            \"duracion\": 10\n",
      "        }\n",
      "    ],\n",
      "    \"descripcion de la experiencia\": \"El candidato ha acumulado una experiencia excepcional en el campo de la inteligencia artificial generativa, destacándose especialmente en su rol como Web Publisher y Generative AI Researcher en 'Talking to Chatbots, by Reddgr', donde ha trabajado durante más de 18 años. Esta experiencia es fundamental, ya que refleja un profundo conocimiento y habilidades en la investigación y aplicación de tecnologías de IA generativa. Además, su paso por IBM en varios roles relacionados con soluciones cognitivas y analítica de datos, junto con su experiencia en Acoustic, complementan su perfil técnico y estratégico. La combinación de su extensa trayectoria y la relevancia de sus posiciones previas han llevado a que obtenga la puntuación máxima de 100, evidenciando su idoneidad para el puesto de Generative AI Engineer.\"\n",
      "}\n",
      "Descripción de la experiencia:\n",
      "El candidato ha acumulado una experiencia excepcional en el campo de la inteligencia artificial generativa, destacándose\n",
      "especialmente en su rol como Web Publisher y Generative AI Researcher en 'Talking to Chatbots, by Reddgr', donde ha\n",
      "trabajado durante más de 18 años. Esta experiencia es fundamental, ya que refleja un profundo conocimiento y habilidades\n",
      "en la investigación y aplicación de tecnologías de IA generativa. Además, su paso por IBM en varios roles relacionados\n",
      "con soluciones cognitivas y analítica de datos, junto con su experiencia en Acoustic, complementan su perfil técnico y\n",
      "estratégico. La combinación de su extensa trayectoria y la relevancia de sus posiciones previas han llevado a que\n",
      "obtenga la puntuación máxima de 100, evidenciando su idoneidad para el puesto de Generative AI Engineer.\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de ejecución:\n",
    "job_text = \"Generative AI engineer\"\n",
    "cv_sample_path = '../../ejemplos_cvs/DavidGR_cv.txt' # Ruta al fichero de texto con un currículo de ejemplo\n",
    "with open(cv_sample_path, 'r') as file:\n",
    "    cv_text = file.read()\n",
    "# Prompts:\n",
    "with open('../prompts/ner_pre_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    ner_pre_prompt = f.read()\n",
    "with open('../prompts/system_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    system_prompt = f.read()\n",
    "with open('../prompts/user_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "# Esquemas JSON:\n",
    "with open('../json/ner_schema.json', 'r', encoding='utf-8') as f:\n",
    "    ner_schema = json.load(f)\n",
    "with open('../json/response_schema.json', 'r', encoding='utf-8') as f:\n",
    "    response_schema = json.load(f)\n",
    "\n",
    "\n",
    "procesador_cvs_prueba_final = ProcesadorCV(api_key, cv_text, job_text, ner_pre_prompt, \n",
    "                                           system_prompt, user_prompt, ner_schema, response_schema)\n",
    "req_experience = 48 # Experiencia requerida en meses\n",
    "positions_cap=10 # Número máximo de puestos a considerar\n",
    "dist_threshold_low=0.5 # Distancia límite para considerar un puesto equivalente\n",
    "dist_threshold_high=0.7 # Distancia límite para considerar un puesto no relevante\n",
    "dict_respuesta = procesador_cvs_prueba_final.procesar_cv_completo(req_experience=req_experience,\n",
    "                                                positions_cap=positions_cap,\n",
    "                                                dist_threshold_low=dist_threshold_low,\n",
    "                                                dist_threshold_high=dist_threshold_high\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de la aplicación Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cv(job_text, cv_text_input, cv_file, req_experience, dist_threshold_low, dist_threshold_high):\n",
    "    if dist_threshold_low >= dist_threshold_high:\n",
    "        return {\"error\": \"dist_threshold_low debe ser más bajo que dist_threshold_high.\"}\n",
    "    \n",
    "    if cv_file is not None:\n",
    "        with open(cv_file.name, 'r', encoding='utf-8') as file:\n",
    "            cv_text = file.read()\n",
    "    elif cv_text_input.strip():\n",
    "        cv_text = cv_text_input\n",
    "    else:\n",
    "        return {\"error\": \"Por favor, introduce el CV o sube un fichero.\"}\n",
    "\n",
    "    try:\n",
    "        procesador = ProcesadorCV(api_key, cv_text, job_text, ner_pre_prompt, \n",
    "                                  system_prompt, user_prompt, ner_schema, response_schema)\n",
    "        positions_cap = 10  # Example fixed value\n",
    "        dict_respuesta = procesador.procesar_cv_completo(\n",
    "            req_experience=req_experience,\n",
    "            positions_cap=positions_cap,\n",
    "            dist_threshold_low=dist_threshold_low,\n",
    "            dist_threshold_high=dist_threshold_high\n",
    "        )\n",
    "        return dict_respuesta\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error en el procesamiento: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the processing function\n",
    "def process_cv(job_text, cv_text, req_experience, positions_cap, dist_threshold_low, dist_threshold_high):\n",
    "    if dist_threshold_low >= dist_threshold_high:\n",
    "        return {\"error\": \"dist_threshold_low must be less than dist_threshold_high.\"}\n",
    "    \n",
    "    if not isinstance(cv_text, str) or not cv_text.strip():\n",
    "        return {\"error\": \"Invalid CV text. Please provide valid text input.\"}\n",
    "\n",
    "    try:\n",
    "        procesador = ProcesadorCV(api_key, cv_text, job_text, ner_pre_prompt, \n",
    "                                  system_prompt, user_prompt, ner_schema, response_schema)\n",
    "        dict_respuesta = procesador.procesar_cv_completo(\n",
    "            req_experience=req_experience,\n",
    "            positions_cap=positions_cap,\n",
    "            dist_threshold_low=dist_threshold_low,\n",
    "            dist_threshold_high=dist_threshold_high\n",
    "        )\n",
    "        return dict_respuesta\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Processing error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente inicializado como <openai.OpenAI object at 0x000001686A135B50>\n",
      "Respuesta:\n",
      " {\n",
      "    \"puntuacion\": 100,\n",
      "    \"experiencia\": [\n",
      "        {\n",
      "            \"empresa\": \"Talking to Chatbots, by Reddgr\",\n",
      "            \"puesto\": \"Web Publisher and Generative AI Researcher\",\n",
      "            \"duracion\": 218\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"MBD Analytics\",\n",
      "            \"puesto\": \"Business Intelligence Consultant\",\n",
      "            \"duracion\": 10\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"Deloitte España\",\n",
      "            \"puesto\": \"IT Strategy Consultant\",\n",
      "            \"duracion\": 4\n",
      "        }\n",
      "    ],\n",
      "    \"descripcion de la experiencia\": \"El candidato ha acumulado una experiencia excepcional en el campo de la inteligencia artificial generativa, destacando especialmente su rol como Web Publisher and Generative AI Researcher en Talking to Chatbots, by Reddgr, donde trabajó durante más de 18 años. Esta experiencia no solo supera ampliamente los 48 meses requeridos, sino que también se alinea perfectamente con las competencias necesarias para el puesto. Además, aunque las posiciones en MBD Analytics y Deloitte España son menos relevantes en términos de duración y relación directa con la IA generativa, contribuyen a un perfil diverso y sólido. La puntuación de 100 refleja la alta relevancia y duración de la experiencia en roles directamente relacionados con la oferta.\"\n",
      "}\n",
      "Descripción de la experiencia:\n",
      "El candidato ha acumulado una experiencia excepcional en el campo de la inteligencia artificial generativa, destacando\n",
      "especialmente su rol como Web Publisher and Generative AI Researcher en Talking to Chatbots, by Reddgr, donde trabajó\n",
      "durante más de 18 años. Esta experiencia no solo supera ampliamente los 48 meses requeridos, sino que también se alinea\n",
      "perfectamente con las competencias necesarias para el puesto. Además, aunque las posiciones en MBD Analytics y Deloitte\n",
      "España son menos relevantes en términos de duración y relación directa con la IA generativa, contribuyen a un perfil\n",
      "diverso y sólido. La puntuación de 100 refleja la alta relevancia y duración de la experiencia en roles directamente\n",
      "relacionados con la oferta.\n"
     ]
    }
   ],
   "source": [
    "# Define Gradio interface components\n",
    "job_text_input = gr.Textbox(label=\"Título oferta de trabajo\", lines=1, placeholder=\"Ingresa el título de la oferta de trabajo\")\n",
    "cv_text_input = gr.Textbox(label=\"CV en formato texto\", lines=10, placeholder=\"Ingresa el texto del CV\")\n",
    "req_experience_input = gr.Number(label=\"Experiencia requerida (en meses)\", value=48, precision=0)\n",
    "positions_cap_input = gr.Number(label=\"Número máximo de puestos a considerar (positions_cap)\", value=10, precision=0)\n",
    "dist_threshold_low_slider = gr.Slider(label=\"Distancia mínima (dist_threshold_low)\", minimum=0, maximum=1, value=0.5, step=0.05)\n",
    "dist_threshold_high_slider = gr.Slider(label=\"Distancia máxima (dist_threshold_high)\", minimum=0, maximum=1, value=0.7, step=0.05)\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=process_cv,\n",
    "    inputs=[\n",
    "        job_text_input, \n",
    "        cv_text_input, \n",
    "        req_experience_input, \n",
    "        positions_cap_input, \n",
    "        dist_threshold_low_slider, \n",
    "        dist_threshold_high_slider\n",
    "    ],\n",
    "    outputs=\"json\",\n",
    "    title=\"Procesador de CVs con LLM\",\n",
    "    description=\"Introduce el título de la oferta de trabajo, el texto del CV, y ajusta los parámetros para procesar el CV con el modelo.\",\n",
    "    examples=[\n",
    "        [\"Generative AI Engineer\", \"Sample CV Text\", 48, 10, 0.5, 0.7]\n",
    "    ],\n",
    "    live=True\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
