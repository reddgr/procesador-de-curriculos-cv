{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del notebook con OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key: sk-proj-****************************************************************************************************************************************************-amA_5sA\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "sys.path.append('../src')\n",
    "from procesador_de_cvs_con_llm import ProcesadorCV\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../../../../../../../apis/.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "unmasked_chars = 8\n",
    "masked_key = api_key[:unmasked_chars] + '*' * (len(api_key) - unmasked_chars*2) + api_key[-unmasked_chars:]\n",
    "print(f\"API key: {masked_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba del módulo de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente inicializado como <openai.OpenAI object at 0x00000168642D44D0>\n",
      "Respuesta:\n",
      " {\n",
      "    \"puntuacion\": 100,\n",
      "    \"experiencia\": [\n",
      "        {\n",
      "            \"empresa\": \"Talking to Chatbots, by Reddgr\",\n",
      "            \"puesto\": \"Web Publisher and Generative AI Researcher\",\n",
      "            \"duracion\": 218\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"IBM\",\n",
      "            \"puesto\": \"Relationship Manager | Cognitive Solutions SaaS\",\n",
      "            \"duracion\": 43\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"Acoustic\",\n",
      "            \"puesto\": \"Principal Consultant | Martech SaaS\",\n",
      "            \"duracion\": 35\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"IBM\",\n",
      "            \"puesto\": \"Engagement Manager | B2B SaaS Retail Analytics\",\n",
      "            \"duracion\": 9\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"IBM\",\n",
      "            \"puesto\": \"Engagement Manager, in support of Acoustic | B2B SaaS Retail Analytics\",\n",
      "            \"duracion\": 10\n",
      "        },\n",
      "        {\n",
      "            \"empresa\": \"MBD Analytics\",\n",
      "            \"puesto\": \"Business Intelligence Consultant\",\n",
      "            \"duracion\": 10\n",
      "        }\n",
      "    ],\n",
      "    \"descripcion de la experiencia\": \"El candidato ha acumulado una experiencia excepcional en el campo de la inteligencia artificial generativa, destacándose especialmente en su rol como Web Publisher y Generative AI Researcher en 'Talking to Chatbots, by Reddgr', donde ha trabajado durante más de 18 años. Esta experiencia es fundamental, ya que refleja un profundo conocimiento y habilidades en la investigación y aplicación de tecnologías de IA generativa. Además, su paso por IBM en varios roles relacionados con soluciones cognitivas y analítica de datos, junto con su experiencia en Acoustic, complementan su perfil técnico y estratégico. La combinación de su extensa trayectoria y la relevancia de sus posiciones previas han llevado a que obtenga la puntuación máxima de 100, evidenciando su idoneidad para el puesto de Generative AI Engineer.\"\n",
      "}\n",
      "Descripción de la experiencia:\n",
      "El candidato ha acumulado una experiencia excepcional en el campo de la inteligencia artificial generativa, destacándose\n",
      "especialmente en su rol como Web Publisher y Generative AI Researcher en 'Talking to Chatbots, by Reddgr', donde ha\n",
      "trabajado durante más de 18 años. Esta experiencia es fundamental, ya que refleja un profundo conocimiento y habilidades\n",
      "en la investigación y aplicación de tecnologías de IA generativa. Además, su paso por IBM en varios roles relacionados\n",
      "con soluciones cognitivas y analítica de datos, junto con su experiencia en Acoustic, complementan su perfil técnico y\n",
      "estratégico. La combinación de su extensa trayectoria y la relevancia de sus posiciones previas han llevado a que\n",
      "obtenga la puntuación máxima de 100, evidenciando su idoneidad para el puesto de Generative AI Engineer.\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de ejecución:\n",
    "job_text = \"Generative AI engineer\"\n",
    "cv_sample_path = '../../ejemplos_cvs/DavidGR_cv.txt' # Ruta al fichero de texto con un currículo de ejemplo\n",
    "with open(cv_sample_path, 'r') as file:\n",
    "    cv_text = file.read()\n",
    "# Prompts:\n",
    "with open('../prompts/ner_pre_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    ner_pre_prompt = f.read()\n",
    "with open('../prompts/system_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    system_prompt = f.read()\n",
    "with open('../prompts/user_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    user_prompt = f.read()\n",
    "# Esquemas JSON:\n",
    "with open('../json/ner_schema.json', 'r', encoding='utf-8') as f:\n",
    "    ner_schema = json.load(f)\n",
    "with open('../json/response_schema.json', 'r', encoding='utf-8') as f:\n",
    "    response_schema = json.load(f)\n",
    "\n",
    "\n",
    "procesador_cvs_prueba_final = ProcesadorCV(api_key, cv_text, job_text, ner_pre_prompt, \n",
    "                                           system_prompt, user_prompt, ner_schema, response_schema)\n",
    "req_experience = 48 # Experiencia requerida en meses\n",
    "positions_cap=10 # Número máximo de puestos a considerar\n",
    "dist_threshold_low=0.5 # Distancia límite para considerar un puesto equivalente\n",
    "dist_threshold_high=0.7 # Distancia límite para considerar un puesto no relevante\n",
    "dict_respuesta = procesador_cvs_prueba_final.procesar_cv_completo(req_experience=req_experience,\n",
    "                                                positions_cap=positions_cap,\n",
    "                                                dist_threshold_low=dist_threshold_low,\n",
    "                                                dist_threshold_high=dist_threshold_high\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de la aplicación Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de carga de la aplicación de \"backend\" para la interfaz Gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cv(job_text, cv_text, req_experience, positions_cap, dist_threshold_low, dist_threshold_high):\n",
    "    if dist_threshold_low >= dist_threshold_high:\n",
    "        return {\"error\": \"dist_threshold_low debe ser más bajo que dist_threshold_high.\"}\n",
    "    \n",
    "    if not isinstance(cv_text, str) or not cv_text.strip():\n",
    "        return {\"error\": \"Por favor, introduce el CV o sube un fichero.\"}\n",
    "\n",
    "    try:\n",
    "        procesador = ProcesadorCV(api_key, cv_text, job_text, ner_pre_prompt, \n",
    "                                  system_prompt, user_prompt, ner_schema, response_schema)\n",
    "        dict_respuesta = procesador.procesar_cv_completo(\n",
    "            req_experience=req_experience,\n",
    "            positions_cap=positions_cap,\n",
    "            dist_threshold_low=dist_threshold_low,\n",
    "            dist_threshold_high=dist_threshold_high\n",
    "        )\n",
    "        return dict_respuesta\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error en el procesamiento: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interfaz de Gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7882\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fichero de ejemplo para autocompletar (opción que aparece en la parte de abajo de la interfaz de usuario):\n",
    "with open('../cv_examples/reddgr_cv.txt', 'r') as file:\n",
    "    cv_example = file.read()\n",
    "\n",
    "# Componentes de la aplicación:\n",
    "job_text_input = gr.Textbox(label=\"Título oferta de trabajo\", lines=1, placeholder=\"Introduce el título de la oferta de trabajo\")\n",
    "cv_text_input = gr.Textbox(label=\"CV en formato texto\", lines=5, max_lines=5, placeholder=\"Introduce el texto del CV\")\n",
    "req_experience_input = gr.Number(label=\"Experiencia requerida (en meses)\", value=48, precision=0)\n",
    "positions_cap_input = gr.Number(label=\"Número máximo de puestos a extraer\", value=10, precision=0)\n",
    "dist_threshold_low_slider = gr.Slider(label=\"Umbral mínimo de distancia de embeddings (puesto equivalente)\", \n",
    "                                      minimum=0, maximum=1, value=0.5, step=0.05)\n",
    "dist_threshold_high_slider = gr.Slider(label=\"Umbral máximo de distancia de embeddings (puesto irrelevante)\", \n",
    "                                       minimum=0, maximum=1, value=0.7, step=0.05)\n",
    "submit_button = gr.Button(\"Procesar\")\n",
    "\n",
    "# Código CSS para truncar el texto de ejemplo en la interfaz (bloque \"Examples\" en la parte de abajo):\n",
    "css = \"\"\"\n",
    "        table tbody tr {\n",
    "            height: 2.5em; /* Set a fixed height for the rows */\n",
    "            overflow: hidden; /* Hide overflow content */\n",
    "        }\n",
    "\n",
    "        table tbody tr td {\n",
    "            overflow: hidden; /* Ensure content within cells doesn't overflow */\n",
    "            text-overflow: ellipsis; /* Add ellipsis for overflowing text */\n",
    "            white-space: nowrap; /* Prevent text from wrapping */\n",
    "            vertical-align: middle; /* Align text vertically within the fixed height */\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "# Interfaz Gradio:\n",
    "interface = gr.Interface(\n",
    "    fn=process_cv,\n",
    "    inputs=[\n",
    "        job_text_input, \n",
    "        cv_text_input, \n",
    "        req_experience_input, \n",
    "        positions_cap_input, \n",
    "        dist_threshold_low_slider, \n",
    "        dist_threshold_high_slider\n",
    "    ],\n",
    "    outputs=\"json\",\n",
    "    title=\"Procesador de CVs con LLM\",\n",
    "    description=(\"Introduce el título de la oferta de trabajo, el texto del CV, y ajusta los parámetros para analizar la candidatura. \"\n",
    "                 \"Puedes utilizar algunos de los ejemplos proporcionados en la parte inferior. Haz click en los ejemplos para autocompletar.\"),\n",
    "    examples=[\n",
    "        [\"Cajero de supermercado\", \"Trabajo de charcutero desde 2021. Antes trabajé 2 meses de camarero en un bar de tapas.\", 48, 10, 0.5, 0.7],\n",
    "        [\"Generative AI Engineer\", cv_example, 48, 10, 0.5, 0.7]\n",
    "    ],\n",
    "    live=False,\n",
    "    allow_flagging=\"never\",  # Disables the \"Flag\" button as there is no flag handler yet\n",
    "    css=css,\n",
    "    article=(\n",
    "            \"<footer><p>Puedes consultar el código completo de esta app y los notebooks explicativos en \"\n",
    "            \"<a href='https://github.com/reddgr' target='_blank'>GitHub</a></p>\"\n",
    "            \"<p>© 2024 <a href='https://talkingtochatbots.com' target='_blank'>talkingtochatbots.com</a></p></footer>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Lanzar la aplicación:\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
